{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"A100","authorship_tag":"ABX9TyM32icQsar13T1z1PAVuWhJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Modes of action (OCD) with Isoacute Comparison"],"metadata":{"id":"mwI-13tAwMoG"}},{"cell_type":"code","source":["!pip install --upgrade sympy\n","# Then restart runtime (Runtime -> Restart runtime)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TisL2PAqxRHD","executionInfo":{"status":"ok","timestamp":1769052912857,"user_tz":-480,"elapsed":9223,"user":{"displayName":"Ngo Cheung","userId":"02091267041339546959"}},"outputId":"cd0167c1-75e4-4fd4-f533-bcfba7867158"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (1.14.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy) (1.3.0)\n"]}]},{"cell_type":"code","source":["#!/usr/bin/env python3\n","\"\"\"\n","================================================================================\n","COMPUTATIONAL MODEL VALIDATING THE OCD SYNAPTIC PRUNING HYPOTHESIS\n","WITH MULTI-MECHANISM ANTIDEPRESSANT COMPARISON\n","================================================================================\n","\n","This model extends the OCD framework to compare three distinct treatment mechanisms:\n","- KETAMINE: Rapid structural repair via synaptogenesis\n","- SSRI: Gradual functional stabilization with fixed structure\n","- NEUROSTEROID: Rapid functional damping via tonic inhibition\n","\n","All mechanisms are modeled through network architecture modifications:\n","- Weight masks / regrowth (structural changes)\n","- Multiplicative scaling of hidden states (inhibition)\n","- Activation functions (bounded vs unbounded)\n","- Internal noise injection (stress/adaptation)\n","- Training dynamics (fast vs slow, fixed vs dynamic weights)\n","\n","THEORETICAL FRAMEWORK:\n","----------------------\n","1. KETAMINE-LIKE: Rapid structural synaptogenesis + brief consolidation\n","2. SSRI-LIKE: Functional stabilization via extended low-LR training + noise reduction\n","3. NEUROSTEROID-LIKE: Tonic GABAergic inhibition (medication-dependent)\n","\n","KEY COMPARISONS:\n","----------------\n","- Acute effects: Immediate post-treatment symptom reduction\n","- Long-term/relapse risk: Resistance to secondary pruning, off-medication reversal\n","\n","NEW IN VERSION 3.1 - ISO-DOSE COMPARISON:\n","-----------------------------------------\n","- Quantifiable dosing metrics for fair cross-mechanism comparison\n","- L1/L2 weight change norms as mechanism-agnostic \"dose\" proxy\n","- Synaptic turnover measurement\n","- Parameter sweeps to match dose across treatments\n","- Efficiency analysis: outcome per unit dose\n","\n","Author: Computational Psychiatry Research\n","Date: January 2026\n","Version: 3.1 (Iso-Dose Fair Comparison Pipeline)\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","import numpy as np\n","from typing import List, Tuple, Optional, Dict, Any, Union\n","from dataclasses import dataclass, field\n","from enum import Enum\n","import copy\n","import warnings\n","from collections import defaultdict\n","import time\n","\n","warnings.filterwarnings('ignore')\n","\n","# =============================================================================\n","# CONFIGURATION\n","# =============================================================================\n","\n","CONFIG = {\n","    # -------------------------------------------------------------------------\n","    # Architecture Parameters\n","    # -------------------------------------------------------------------------\n","    'input_dim': 2,\n","    'hidden_dims': [128, 64],\n","    'output_dim': 4,\n","    'num_gru_layers': 2,\n","\n","    # -------------------------------------------------------------------------\n","    # Training Parameters\n","    # -------------------------------------------------------------------------\n","    'batch_size': 32,\n","    'baseline_lr': 1e-3,\n","    'finetune_lr': 5e-4,\n","    'baseline_epochs': 50,\n","    'regrowth_epochs': 30,\n","\n","    # -------------------------------------------------------------------------\n","    # Sequence/Task Parameters\n","    # -------------------------------------------------------------------------\n","    'seq_len': 200,\n","    'n_train_sequences': 500,\n","    'n_test_sequences': 100,\n","    'switch_interval': 50,\n","    'n_rules': 4,\n","\n","    # -------------------------------------------------------------------------\n","    # Pruning Parameters\n","    # -------------------------------------------------------------------------\n","    'target_sparsities': [0.0, 0.5, 0.7, 0.85, 0.90, 0.93, 0.95, 0.97],\n","    'regrowth_fraction': 0.50,\n","    'regrowth_init_scale': 0.03,\n","    'recurrence_bias': 1.2,\n","\n","    # -------------------------------------------------------------------------\n","    # Treatment Duration Experiment Parameters\n","    # -------------------------------------------------------------------------\n","    'consolidation_epochs': [0, 5, 10, 15, 20],\n","    'relapse_prune_fraction': 0.40,\n","\n","    # -------------------------------------------------------------------------\n","    # Iterative Regimen Experiment Parameters\n","    # -------------------------------------------------------------------------\n","    'acute_regrow_fractions': [0.60, 1.00],\n","    'chronic_cycles': [3, 6, 10],\n","    'per_cycle_regrow': 0.40,\n","    'per_cycle_epochs': 5,\n","    'final_consolidation': 15,\n","\n","    # -------------------------------------------------------------------------\n","    # Stress/Noise Parameters\n","    # -------------------------------------------------------------------------\n","    'stress_levels': [0.0, 0.1, 0.3],\n","    'glutamate_noise_levels': [0.0, 0.2, 0.5],\n","    'relapse_noise': 0.2,\n","\n","    # =========================================================================\n","    # MULTI-MECHANISM ANTIDEPRESSANT COMPARISON\n","    # =========================================================================\n","    'ocd_prune_sparsity': 0.95,\n","    'comparison_ketamine_regrow': 0.60,\n","    'comparison_ketamine_epochs': 10,\n","    'comparison_ssri_epochs': 120,\n","    'comparison_ssri_lr': 1e-5,\n","    'comparison_ssri_initial_stress': 0.4,\n","    'comparison_neurosteroid_strength': 0.65,\n","    'comparison_neurosteroid_use_tanh': True,\n","    'comparison_neurosteroid_epochs': 8,\n","\n","    # =========================================================================\n","    # ISO-DOSE COMPARISON PARAMETERS (NEW)\n","    # =========================================================================\n","    'iso_dose_norm_type': 'l1',\n","    'iso_dose_target_doses': [0.005, 0.010, 0.020, 0.040],\n","    'iso_dose_tolerance': 0.002,\n","    'iso_dose_turnover_threshold': 0.10,\n","\n","    # Parameter sweep ranges\n","    'ketamine_regrow_sweep': [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80],\n","    'ssri_epochs_sweep': [20, 40, 60, 80, 100, 120, 160, 200],\n","    'ssri_lr_sweep': [1e-6, 5e-6, 1e-5, 2e-5, 5e-5],\n","    'neurosteroid_strength_sweep': [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85],\n","\n","    # -------------------------------------------------------------------------\n","    # Reproducibility\n","    # -------------------------------------------------------------------------\n","    'seed': 42,\n","    'n_seeds': 3,\n","}\n","\n","# Global device\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","def set_seed(seed: int):\n","    \"\"\"Ensure reproducibility across runs.\"\"\"\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","\n","def print_section_header(title: str, width: int = 80, char: str = \"=\"):\n","    \"\"\"Print a formatted section header.\"\"\"\n","    print(f\"\\n{char * width}\")\n","    print(f\"{title.center(width)}\")\n","    print(f\"{char * width}\")\n","\n","\n","def print_subsection_header(title: str, width: int = 60, char: str = \"-\"):\n","    \"\"\"Print a formatted subsection header.\"\"\"\n","    print(f\"\\n{char * width}\")\n","    print(f\"  {title}\")\n","    print(f\"{char * width}\")\n","\n","\n","# =============================================================================\n","# DOSING METRICS - MECHANISM-AGNOSTIC QUANTIFICATION\n","# =============================================================================\n","\n","def compute_weight_change_norm(\n","    model_pre_state: Dict[str, torch.Tensor],\n","    model_post: nn.Module,\n","    norm_type: str = 'l1'\n",") -> float:\n","    \"\"\"\n","    Compute total weight change magnitude as mechanism-agnostic dose proxy.\n","\n","    Returns normalized dose (total change / total parameters).\n","    \"\"\"\n","    delta = 0.0\n","    total_params = 0\n","\n","    for name, param in model_post.named_parameters():\n","        if 'weight' in name and name in model_pre_state:\n","            diff = (param.data - model_pre_state[name]).abs()\n","            total_params += param.numel()\n","            if norm_type == 'l1':\n","                delta += diff.sum().item()\n","            elif norm_type == 'l2':\n","                delta += (diff ** 2).sum().item()\n","\n","    if norm_type == 'l2':\n","        delta = delta ** 0.5\n","\n","    return delta / total_params if total_params > 0 else 0.0\n","\n","\n","def compute_synaptic_turnover(\n","    model_pre_state: Dict[str, torch.Tensor],\n","    model_post: nn.Module,\n","    threshold: float = 0.10\n",") -> float:\n","    \"\"\"\n","    Compute fraction of synapses with significant weight changes.\n","\n","    Captures \"how many synapses were meaningfully modified\" (> threshold relative change).\n","    \"\"\"\n","    changed = 0\n","    total = 0\n","\n","    for name, param in model_post.named_parameters():\n","        if 'weight' in name and name in model_pre_state:\n","            pre_weights = model_pre_state[name]\n","            relative_change = (param.data - pre_weights).abs() / (pre_weights.abs().clamp(min=1e-8))\n","            changed += (relative_change > threshold).sum().item()\n","            total += param.numel()\n","\n","    return changed / total if total > 0 else 0.0\n","\n","\n","def compute_sparsity_change(\n","    model_pre_state: Dict[str, torch.Tensor],\n","    model_post: nn.Module\n",") -> float:\n","    \"\"\"Compute absolute change in network sparsity.\"\"\"\n","    def get_sparsity(state_dict):\n","        total = 0\n","        zeros = 0\n","        for name, tensor in state_dict.items():\n","            if 'weight' in name:\n","                total += tensor.numel()\n","                zeros += (tensor.abs() < 1e-8).sum().item()\n","        return zeros / total if total > 0 else 0.0\n","\n","    pre_sparsity = get_sparsity(model_pre_state)\n","    post_sparsity = get_sparsity({n: p.data for n, p in model_post.named_parameters()})\n","\n","    return abs(post_sparsity - pre_sparsity)\n","\n","\n","@dataclass\n","class DoseMetrics:\n","    \"\"\"Container for all dosing quantification metrics.\"\"\"\n","    l1_norm: float = 0.0\n","    l2_norm: float = 0.0\n","    synaptic_turnover: float = 0.0\n","    sparsity_change: float = 0.0\n","\n","    @property\n","    def primary_dose(self) -> float:\n","        \"\"\"Primary dose metric (L1 norm by default).\"\"\"\n","        return self.l1_norm\n","\n","\n","def compute_all_dose_metrics(\n","    model_pre_state: Dict[str, torch.Tensor],\n","    model_post: nn.Module,\n","    turnover_threshold: float = None\n",") -> DoseMetrics:\n","    \"\"\"Compute all dose quantification metrics.\"\"\"\n","    if turnover_threshold is None:\n","        turnover_threshold = CONFIG['iso_dose_turnover_threshold']\n","\n","    return DoseMetrics(\n","        l1_norm=compute_weight_change_norm(model_pre_state, model_post, 'l1'),\n","        l2_norm=compute_weight_change_norm(model_pre_state, model_post, 'l2'),\n","        synaptic_turnover=compute_synaptic_turnover(model_pre_state, model_post, turnover_threshold),\n","        sparsity_change=compute_sparsity_change(model_pre_state, model_post)\n","    )\n","\n","\n","# =============================================================================\n","# RULE DEFINITIONS FOR COGNITIVE FLEXIBILITY TASK\n","# =============================================================================\n","\n","class Rule(Enum):\n","    \"\"\"Classification rules analogous to Wisconsin Card Sorting Test dimensions.\"\"\"\n","    X_SIGN = 0\n","    Y_SIGN = 1\n","    QUADRANT = 2\n","    DIAGONAL = 3\n","\n","\n","def apply_rule(points: torch.Tensor, rule: int) -> torch.Tensor:\n","    \"\"\"Apply a classification rule to 2D points.\"\"\"\n","    x, y = points[..., 0], points[..., 1]\n","\n","    if rule == Rule.X_SIGN.value:\n","        labels = ((x >= 0).long() * 2 + (y >= 0).long())\n","    elif rule == Rule.Y_SIGN.value:\n","        labels = ((y >= 0).long() * 2 + (x >= 0).long())\n","    elif rule == Rule.QUADRANT.value:\n","        labels = ((x >= 0).long() + (y >= 0).long() * 2)\n","    elif rule == Rule.DIAGONAL.value:\n","        main_diag = (y >= x).long()\n","        anti_diag = (y >= -x).long()\n","        labels = main_diag * 2 + anti_diag\n","    else:\n","        raise ValueError(f\"Unknown rule: {rule}\")\n","\n","    return labels\n","\n","\n","# =============================================================================\n","# DATA GENERATION\n","# =============================================================================\n","\n","def generate_base_points(n_points: int, noise: float = 0.8) -> torch.Tensor:\n","    \"\"\"Generate 2D points from 4 Gaussian clusters centered in each quadrant.\"\"\"\n","    centers = torch.tensor([\n","        [1.5, 1.5], [-1.5, 1.5], [-1.5, -1.5], [1.5, -1.5],\n","    ], dtype=torch.float32)\n","\n","    cluster_idx = torch.randint(0, 4, (n_points,))\n","    points = centers[cluster_idx] + torch.randn(n_points, 2) * noise\n","\n","    return points\n","\n","\n","def generate_rule_switch_sequences(\n","    n_sequences: int,\n","    seq_len: int,\n","    switch_interval: int,\n","    noise: float = 0.8,\n","    deterministic_switches: bool = False\n",") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n","    \"\"\"Generate sequences with rule switches for cognitive flexibility testing.\"\"\"\n","    all_data = []\n","    all_labels = []\n","    all_rules = []\n","\n","    for _ in range(n_sequences):\n","        points = generate_base_points(seq_len, noise=noise)\n","        rules = torch.zeros(seq_len, dtype=torch.long)\n","        current_rule = torch.randint(0, CONFIG['n_rules'], (1,)).item()\n","\n","        if deterministic_switches:\n","            switch_points = set(range(switch_interval, seq_len, switch_interval))\n","        else:\n","            n_switches = max(1, seq_len // switch_interval)\n","            valid_range = list(range(20, seq_len - 20))\n","            if len(valid_range) >= n_switches:\n","                switch_points = set(np.random.choice(\n","                    valid_range, size=n_switches, replace=False\n","                ))\n","            else:\n","                switch_points = set(valid_range)\n","\n","        for t in range(seq_len):\n","            if t in switch_points:\n","                new_rule = (current_rule + np.random.randint(1, CONFIG['n_rules'])) % CONFIG['n_rules']\n","                current_rule = new_rule\n","            rules[t] = current_rule\n","\n","        labels = torch.zeros(seq_len, dtype=torch.long)\n","        for t in range(seq_len):\n","            labels[t] = apply_rule(points[t:t+1], rules[t].item())[0]\n","\n","        all_data.append(points)\n","        all_labels.append(labels)\n","        all_rules.append(rules)\n","\n","    return torch.stack(all_data), torch.stack(all_labels), torch.stack(all_rules)\n","\n","\n","def create_rule_switch_dataloaders(\n","    n_train: int = None,\n","    n_test: int = None,\n","    seq_len: int = None,\n","    batch_size: int = None\n",") -> Tuple[DataLoader, DataLoader, torch.Tensor]:\n","    \"\"\"Create train and test dataloaders for rule-switching task.\"\"\"\n","    n_train = n_train or CONFIG['n_train_sequences']\n","    n_test = n_test or CONFIG['n_test_sequences']\n","    seq_len = seq_len or CONFIG['seq_len']\n","    batch_size = batch_size or CONFIG['batch_size']\n","\n","    train_data, train_labels, train_rules = generate_rule_switch_sequences(\n","        n_train, seq_len, CONFIG['switch_interval'], deterministic_switches=False\n","    )\n","    test_data, test_labels, test_rules = generate_rule_switch_sequences(\n","        n_test, seq_len, CONFIG['switch_interval'], deterministic_switches=True\n","    )\n","\n","    train_dataset = TensorDataset(train_data, train_labels, train_rules)\n","    test_dataset = TensorDataset(test_data, test_labels, test_rules)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader, test_rules\n","\n","\n","# =============================================================================\n","# RECURRENT NETWORK ARCHITECTURE (CSTC LOOP MODEL) - ENHANCED\n","# =============================================================================\n","\n","class CSTCNetwork(nn.Module):\n","    \"\"\"\n","    Recurrent network modeling cortico-striato-thalamo-cortical (CSTC) loops.\n","    \"\"\"\n","\n","    def __init__(self, hidden_dims: List[int] = None, num_layers: int = None):\n","        super().__init__()\n","        if hidden_dims is None:\n","            hidden_dims = CONFIG['hidden_dims']\n","        if num_layers is None:\n","            num_layers = CONFIG['num_gru_layers']\n","\n","        self.hidden_dim = hidden_dims[1]\n","        self.num_layers = num_layers\n","\n","        self.input_fc = nn.Linear(CONFIG['input_dim'], hidden_dims[0])\n","\n","        self.gru = nn.GRU(\n","            input_size=hidden_dims[0],\n","            hidden_size=hidden_dims[1],\n","            num_layers=num_layers,\n","            batch_first=True,\n","            dropout=0.1 if num_layers > 1 else 0.0\n","        )\n","\n","        self.output_fc = nn.Linear(hidden_dims[1], CONFIG['output_dim'])\n","\n","        self.relu = nn.ReLU()\n","\n","        self.stress_level = 0.0\n","        self.glutamate_noise = 0.0\n","\n","        self.inhibition_strength = 1.0\n","        self.use_tanh = False\n","\n","        self.register_buffer('input_mask', torch.ones_like(self.input_fc.weight))\n","        self.register_buffer('output_mask', torch.ones_like(self.output_fc.weight))\n","        self.gru_masks = {}\n","\n","    def init_hidden(self, batch_size: int, device: torch.device) -> torch.Tensor:\n","        \"\"\"Initialize GRU hidden state.\"\"\"\n","        return torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n","\n","    def set_inhibition(self, strength: float, use_tanh: bool = False):\n","        \"\"\"Apply neurosteroid-like tonic inhibition.\"\"\"\n","        self.inhibition_strength = max(0.0, min(1.0, strength))\n","        self.use_tanh = use_tanh\n","\n","    def reduce_stress_gradually(self, epoch: int, total_epochs: int,\n","                                initial_stress: float = 0.4, final_stress: float = 0.0):\n","        \"\"\"SSRI-like: Linearly reduce internal recurrent noise over epochs.\"\"\"\n","        progress = epoch / max(total_epochs - 1, 1)\n","        self.stress_level = initial_stress + progress * (final_stress - initial_stress)\n","\n","    def forward(\n","        self,\n","        x: torch.Tensor,\n","        hidden: Optional[torch.Tensor] = None,\n","        return_hidden: bool = False\n","    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n","        \"\"\"Forward pass through CSTC network.\"\"\"\n","        single_step = x.dim() == 2\n","        if single_step:\n","            x = x.unsqueeze(1)\n","\n","        batch_size, seq_len, _ = x.shape\n","        device = x.device\n","\n","        if hidden is None:\n","            hidden = self.init_hidden(batch_size, device)\n","\n","        if self.glutamate_noise > 0:\n","            x = x + torch.randn_like(x) * self.glutamate_noise\n","\n","        masked_weight = self.input_fc.weight * self.input_mask\n","        h = F.linear(x, masked_weight, self.input_fc.bias)\n","        h = self.relu(h)\n","\n","        h = h * self.inhibition_strength\n","\n","        if self.stress_level > 0:\n","            h = h + torch.randn_like(h) * self.stress_level\n","\n","        gru_out, hidden = self.gru(h, hidden)\n","\n","        gru_out = gru_out * self.inhibition_strength\n","        if self.use_tanh:\n","            gru_out = torch.tanh(gru_out)\n","\n","        if self.stress_level > 0:\n","            gru_out = gru_out + torch.randn_like(gru_out) * self.stress_level * 0.5\n","\n","        masked_output_weight = self.output_fc.weight * self.output_mask\n","        logits = F.linear(gru_out, masked_output_weight, self.output_fc.bias)\n","\n","        if single_step:\n","            logits = logits.squeeze(1)\n","\n","        if return_hidden:\n","            return logits, hidden\n","        return logits, None\n","\n","    def set_stress(self, level: float):\n","        \"\"\"Set internal noise level.\"\"\"\n","        self.stress_level = max(0.0, level)\n","\n","    def set_glutamate_noise(self, level: float):\n","        \"\"\"Set input-only noise for glutamate independence testing.\"\"\"\n","        self.glutamate_noise = max(0.0, level)\n","\n","    def get_sparsity(self) -> float:\n","        \"\"\"Calculate current network sparsity.\"\"\"\n","        total_params = 0\n","        zero_params = 0\n","\n","        for name, param in self.named_parameters():\n","            if 'weight' in name:\n","                total_params += param.numel()\n","                zero_params += (param.abs() < 1e-8).sum().item()\n","\n","        return zero_params / total_params if total_params > 0 else 0.0\n","\n","    def get_treatment_state(self) -> Dict[str, Any]:\n","        \"\"\"Get current treatment-related state for logging.\"\"\"\n","        return {\n","            'stress_level': self.stress_level,\n","            'glutamate_noise': self.glutamate_noise,\n","            'inhibition_strength': self.inhibition_strength,\n","            'use_tanh': self.use_tanh,\n","            'sparsity': self.get_sparsity()\n","        }\n","\n","\n","# =============================================================================\n","# PRUNING MANAGER WITH TREATMENT SIMULATION CAPABILITIES\n","# =============================================================================\n","\n","class CSTCPruningManager:\n","    \"\"\"Manages pruning, regrowth, and relapse simulation for CSTC networks.\"\"\"\n","\n","    def __init__(self, model: CSTCNetwork):\n","        self.model = model\n","        self.original_weights = {}\n","        self.masks = {}\n","        self.history = []\n","        self._save_original_weights()\n","\n","    def _save_original_weights(self):\n","        \"\"\"Store original weights for regrowth restoration.\"\"\"\n","        for name, param in self.model.named_parameters():\n","            if 'weight' in name:\n","                self.original_weights[name] = param.data.clone()\n","                self.masks[name] = torch.ones_like(param.data)\n","\n","    def get_sparsity(self) -> float:\n","        \"\"\"Get current network sparsity.\"\"\"\n","        return self.model.get_sparsity()\n","\n","    def prune_by_magnitude(\n","        self,\n","        sparsity: float,\n","        recurrence_bias: float = None\n","    ) -> Dict[str, Any]:\n","        \"\"\"Apply global magnitude-based pruning.\"\"\"\n","        if recurrence_bias is None:\n","            recurrence_bias = CONFIG['recurrence_bias']\n","\n","        if sparsity <= 0:\n","            return {'achieved_sparsity': 0.0, 'weights_pruned': 0}\n","\n","        all_weights = []\n","        weight_info = []\n","\n","        for name, param in self.model.named_parameters():\n","            if 'weight' in name and param.requires_grad:\n","                flat_weights = param.data.abs().flatten()\n","\n","                if 'gru' in name and recurrence_bias != 1.0:\n","                    flat_weights = flat_weights / recurrence_bias\n","\n","                all_weights.append(flat_weights)\n","                weight_info.append((name, param))\n","\n","        if not all_weights:\n","            return {'achieved_sparsity': 0.0, 'weights_pruned': 0}\n","\n","        all_weights_cat = torch.cat(all_weights)\n","        k = int(sparsity * all_weights_cat.numel())\n","        if k == 0:\n","            return {'achieved_sparsity': 0.0, 'weights_pruned': 0}\n","\n","        threshold = torch.kthvalue(all_weights_cat, k).values.item()\n","\n","        total_pruned = 0\n","        layer_stats = {}\n","\n","        for name, param in weight_info:\n","            effective_weights = param.data.abs()\n","            if 'gru' in name and recurrence_bias != 1.0:\n","                effective_weights = effective_weights / recurrence_bias\n","\n","            mask = (effective_weights > threshold).float()\n","            pruned_count = (mask == 0).sum().item()\n","\n","            self.masks[name] = mask\n","            param.data *= mask\n","\n","            total_pruned += pruned_count\n","            layer_stats[name] = {\n","                'pruned': pruned_count,\n","                'total': param.numel(),\n","                'layer_sparsity': pruned_count / param.numel()\n","            }\n","\n","            if name == 'input_fc.weight':\n","                self.model.input_mask.copy_(mask)\n","            elif name == 'output_fc.weight':\n","                self.model.output_mask.copy_(mask)\n","\n","        achieved = self.get_sparsity()\n","\n","        self.history.append({\n","            'operation': 'prune_magnitude',\n","            'target_sparsity': sparsity,\n","            'achieved_sparsity': achieved,\n","            'weights_pruned': total_pruned,\n","            'recurrence_bias': recurrence_bias\n","        })\n","\n","        return {\n","            'achieved_sparsity': achieved,\n","            'weights_pruned': total_pruned,\n","            'layer_stats': layer_stats\n","        }\n","\n","    def gradient_guided_regrow(\n","        self,\n","        train_loader: DataLoader = None,\n","        regrow_fraction: float = None,\n","        n_batches: int = 5,\n","        init_scale: float = None\n","    ) -> Dict[str, Any]:\n","        \"\"\"Regrow connections guided by gradient importance.\"\"\"\n","        if regrow_fraction is None:\n","            regrow_fraction = CONFIG['regrowth_fraction']\n","        if init_scale is None:\n","            init_scale = CONFIG['regrowth_init_scale']\n","        if train_loader is None:\n","            train_loader, _, _ = create_rule_switch_dataloaders()\n","\n","        self.model.train()\n","        device = next(self.model.parameters()).device\n","\n","        gradient_importance = {}\n","        for name, param in self.model.named_parameters():\n","            if 'weight' in name:\n","                gradient_importance[name] = torch.zeros_like(param.data)\n","\n","        criterion = nn.CrossEntropyLoss()\n","\n","        for batch_idx, (data, labels, _) in enumerate(train_loader):\n","            if batch_idx >= n_batches:\n","                break\n","\n","            data, labels = data.to(device), labels.to(device)\n","            self.model.zero_grad()\n","\n","            logits, _ = self.model(data)\n","            loss = criterion(logits.view(-1, CONFIG['output_dim']), labels.view(-1))\n","            loss.backward()\n","\n","            for name, param in self.model.named_parameters():\n","                if 'weight' in name and param.grad is not None:\n","                    gradient_importance[name] += param.grad.abs()\n","\n","        total_regrown = 0\n","        layer_stats = {}\n","\n","        for name, param in self.model.named_parameters():\n","            if 'weight' not in name:\n","                continue\n","\n","            mask = self.masks.get(name, torch.ones_like(param.data))\n","            pruned_mask = (mask < 0.5)\n","\n","            if pruned_mask.sum() == 0:\n","                continue\n","\n","            n_regrow = int(regrow_fraction * pruned_mask.sum().item())\n","            if n_regrow == 0:\n","                continue\n","\n","            importance = gradient_importance[name] * pruned_mask.float()\n","            flat_importance = importance.flatten()\n","            n_positive = (flat_importance > 0).sum().item()\n","\n","            if n_positive == 0:\n","                continue\n","\n","            _, top_indices = torch.topk(flat_importance, min(n_regrow, n_positive))\n","\n","            flat_mask = mask.flatten()\n","            flat_param = param.data.flatten()\n","            flat_original = self.original_weights[name].flatten()\n","\n","            for idx in top_indices:\n","                flat_mask[idx] = 1.0\n","                flat_param[idx] = flat_original[idx] * init_scale\n","\n","            new_mask = flat_mask.view_as(mask)\n","            param.data = flat_param.view_as(param.data)\n","            self.masks[name] = new_mask\n","\n","            if name == 'input_fc.weight':\n","                self.model.input_mask.copy_(new_mask)\n","            elif name == 'output_fc.weight':\n","                self.model.output_mask.copy_(new_mask)\n","\n","            regrown_count = len(top_indices)\n","            total_regrown += regrown_count\n","            layer_stats[name] = {\n","                'regrown': regrown_count,\n","                'remaining_pruned': pruned_mask.sum().item() - regrown_count\n","            }\n","\n","        new_sparsity = self.get_sparsity()\n","\n","        self.history.append({\n","            'operation': 'gradient_regrow',\n","            'regrow_fraction': regrow_fraction,\n","            'connections_regrown': total_regrown,\n","            'new_sparsity': new_sparsity\n","        })\n","\n","        return {\n","            'connections_regrown': total_regrown,\n","            'new_sparsity': new_sparsity,\n","            'layer_stats': layer_stats\n","        }\n","\n","    def secondary_prune(\n","        self,\n","        fraction: float,\n","        bias_recurrent: bool = False,\n","        recurrence_multiplier: float = 1.5\n","    ) -> Dict[str, Any]:\n","        \"\"\"Simulate relapse by pruning a fraction of surviving weights.\"\"\"\n","        stats = {}\n","        total_pruned = 0\n","\n","        for name, param in self.model.named_parameters():\n","            if name not in self.masks:\n","                continue\n","\n","            mask = self.masks[name]\n","            active_positions = (mask == 1)\n","            n_active = active_positions.sum().item()\n","\n","            if n_active == 0:\n","                continue\n","\n","            effective_fraction = fraction\n","            if bias_recurrent and 'gru' in name:\n","                effective_fraction = min(fraction * recurrence_multiplier, 0.9)\n","\n","            num_to_prune = int(effective_fraction * n_active)\n","            if num_to_prune == 0:\n","                continue\n","\n","            weights = param.data.abs()\n","            weights_active = weights.clone()\n","            weights_active[~active_positions] = float('inf')\n","\n","            flat_weights = weights_active.flatten()\n","            threshold = torch.kthvalue(flat_weights, num_to_prune).values.item()\n","\n","            prune_mask = (weights <= threshold) & active_positions\n","            mask[prune_mask] = 0\n","            param.data[prune_mask] = 0\n","\n","            pruned_count = prune_mask.sum().item()\n","            total_pruned += pruned_count\n","\n","            stats[name] = {\n","                'pruned': pruned_count,\n","                'remaining': n_active - pruned_count,\n","                'effective_fraction': effective_fraction\n","            }\n","\n","            if name == 'input_fc.weight':\n","                self.model.input_mask.copy_(mask)\n","            elif name == 'output_fc.weight':\n","                self.model.output_mask.copy_(mask)\n","\n","        new_sparsity = self.get_sparsity()\n","\n","        self.history.append({\n","            'operation': 'secondary_prune',\n","            'fraction': fraction,\n","            'bias_recurrent': bias_recurrent,\n","            'total_pruned': total_pruned,\n","            'new_sparsity': new_sparsity\n","        })\n","\n","        return {\n","            'total_pruned': total_pruned,\n","            'new_sparsity': new_sparsity,\n","            'layer_stats': stats\n","        }\n","\n","    def apply_masks(self):\n","        \"\"\"Re-apply masks after training steps to maintain sparsity pattern.\"\"\"\n","        for name, param in self.model.named_parameters():\n","            if name in self.masks:\n","                param.data *= self.masks[name]\n","\n","    def get_history_summary(self) -> str:\n","        \"\"\"Get a formatted summary of all operations.\"\"\"\n","        lines = [\"Pruning Manager History:\"]\n","        for i, op in enumerate(self.history):\n","            lines.append(f\"  {i+1}. {op['operation']}: {op}\")\n","        return \"\\n\".join(lines)\n","\n","\n","# =============================================================================\n","# OCD-SPECIFIC EVALUATION METRICS\n","# =============================================================================\n","\n","@dataclass\n","class OCDMetrics:\n","    \"\"\"Metrics capturing OCD-relevant behavioral phenotypes.\"\"\"\n","\n","    accuracy: float = 0.0\n","    perseverative_error_rate: float = 0.0\n","    switch_cost: float = 0.0\n","    trials_to_recover: float = 0.0\n","    repetition_rate: float = 0.0\n","    repetition_entropy: float = 0.0\n","    output_diversity: float = 0.0\n","    rule_inference_accuracy: float = 0.0\n","    flexibility_index: float = 0.0\n","    sparsity: float = 0.0\n","    stress_level: float = 0.0\n","    glutamate_noise: float = 0.0\n","    inhibition_strength: float = 1.0\n","    use_tanh: bool = False\n","\n","\n","def compute_ocd_metrics(\n","    model: CSTCNetwork,\n","    test_loader: DataLoader,\n","    device: torch.device,\n","    detailed: bool = False\n",") -> OCDMetrics:\n","    \"\"\"Compute comprehensive OCD-relevant metrics.\"\"\"\n","    model.eval()\n","    metrics = OCDMetrics()\n","\n","    all_predictions = []\n","    all_labels = []\n","    all_rules = []\n","    all_correct = []\n","\n","    with torch.no_grad():\n","        for data, labels, rules in test_loader:\n","            data, labels, rules = data.to(device), labels.to(device), rules.to(device)\n","\n","            batch_size, seq_len, _ = data.shape\n","            hidden = model.init_hidden(batch_size, device)\n","\n","            batch_preds = []\n","            for t in range(seq_len):\n","                logits, hidden = model(data[:, t:t+1, :], hidden, return_hidden=True)\n","                preds = logits.squeeze(1).argmax(dim=-1)\n","                batch_preds.append(preds)\n","\n","            batch_preds = torch.stack(batch_preds, dim=1)\n","\n","            all_predictions.append(batch_preds.cpu())\n","            all_labels.append(labels.cpu())\n","            all_rules.append(rules.cpu())\n","            all_correct.append((batch_preds == labels).cpu())\n","\n","    predictions = torch.cat(all_predictions, dim=0)\n","    labels = torch.cat(all_labels, dim=0)\n","    rules = torch.cat(all_rules, dim=0)\n","    correct = torch.cat(all_correct, dim=0)\n","\n","    n_sequences, seq_len = predictions.shape\n","\n","    metrics.accuracy = correct.float().mean().item()\n","\n","    rule_changes = (rules[:, 1:] != rules[:, :-1])\n","\n","    perseverative_errors = 0\n","    perseverative_opportunities = 0\n","    switch_accuracies = []\n","    stable_accuracies = []\n","    recovery_trials_list = []\n","\n","    for seq_idx in range(n_sequences):\n","        switch_points = torch.where(rule_changes[seq_idx])[0] + 1\n","\n","        prev_switch = 0\n","        for switch_t in switch_points:\n","            switch_t = switch_t.item()\n","            if switch_t - prev_switch >= 10:\n","                stable_acc = correct[seq_idx, prev_switch+5:switch_t-5].float().mean().item()\n","                if not np.isnan(stable_acc):\n","                    stable_accuracies.append(stable_acc)\n","            prev_switch = switch_t\n","\n","        for switch_t in switch_points:\n","            switch_t = switch_t.item()\n","            if switch_t >= seq_len - 10:\n","                continue\n","\n","            window_end = min(switch_t + 10, seq_len)\n","            for t in range(switch_t, window_end):\n","                if not correct[seq_idx, t]:\n","                    perseverative_opportunities += 1\n","                    if t > 0 and predictions[seq_idx, t] == predictions[seq_idx, t-1]:\n","                        perseverative_errors += 1\n","\n","            post_acc = correct[seq_idx, switch_t:min(switch_t+5, seq_len)].float().mean().item()\n","\n","            if not np.isnan(post_acc):\n","                switch_accuracies.append(post_acc)\n","\n","            for recovery_t in range(switch_t, min(seq_len - 5, switch_t + 50)):\n","                window_acc = correct[seq_idx, recovery_t:recovery_t+5].float().mean().item()\n","                if window_acc >= 0.8:\n","                    recovery_trials_list.append(recovery_t - switch_t)\n","                    break\n","            else:\n","                recovery_trials_list.append(50)\n","\n","    if perseverative_opportunities > 0:\n","        metrics.perseverative_error_rate = perseverative_errors / perseverative_opportunities\n","\n","    if switch_accuracies and stable_accuracies:\n","        metrics.switch_cost = np.mean(stable_accuracies) - np.mean(switch_accuracies)\n","        metrics.flexibility_index = np.mean(switch_accuracies) / (np.mean(stable_accuracies) + 1e-8)\n","\n","    if recovery_trials_list:\n","        metrics.trials_to_recover = np.mean(recovery_trials_list)\n","\n","    if stable_accuracies:\n","        metrics.rule_inference_accuracy = np.mean(stable_accuracies)\n","\n","    repetitions = (predictions[:, 1:] == predictions[:, :-1]).float()\n","    metrics.repetition_rate = repetitions.mean().item()\n","\n","    output_counts = torch.bincount(predictions.flatten(), minlength=CONFIG['output_dim']).float()\n","    output_probs = output_counts / output_counts.sum()\n","    entropy = -(output_probs * torch.log(output_probs + 1e-8)).sum().item()\n","    max_entropy = np.log(CONFIG['output_dim'])\n","    metrics.repetition_entropy = entropy\n","    metrics.output_diversity = entropy / max_entropy\n","\n","    metrics.sparsity = model.get_sparsity()\n","    metrics.stress_level = model.stress_level\n","    metrics.glutamate_noise = model.glutamate_noise\n","    metrics.inhibition_strength = model.inhibition_strength\n","    metrics.use_tanh = model.use_tanh\n","\n","    return metrics\n","\n","\n","# =============================================================================\n","# TRAINING FUNCTIONS\n","# =============================================================================\n","\n","def train_epoch(\n","    model: CSTCNetwork,\n","    train_loader: DataLoader,\n","    optimizer: torch.optim.Optimizer,\n","    criterion: nn.Module,\n","    device: torch.device,\n","    pruning_manager: Optional[CSTCPruningManager] = None\n",") -> float:\n","    \"\"\"Train for one epoch, maintaining sparsity if pruning manager provided.\"\"\"\n","    model.train()\n","    total_loss = 0.0\n","    n_batches = 0\n","\n","    for data, labels, _ in train_loader:\n","        data, labels = data.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        logits, _ = model(data)\n","\n","        loss = criterion(\n","            logits.view(-1, CONFIG['output_dim']),\n","            labels.view(-1)\n","        )\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","\n","        if pruning_manager is not None:\n","            pruning_manager.apply_masks()\n","\n","        total_loss += loss.item()\n","        n_batches += 1\n","\n","    return total_loss / n_batches\n","\n","\n","def train(\n","    model: CSTCNetwork,\n","    train_loader: DataLoader = None,\n","    test_loader: DataLoader = None,\n","    epochs: int = None,\n","    lr: float = None,\n","    pruning_manager: Optional[CSTCPruningManager] = None,\n","    verbose: bool = True,\n","    eval_interval: int = 10\n",") -> Dict[str, List[float]]:\n","    \"\"\"Full training loop with optional pruning maintenance.\"\"\"\n","    if train_loader is None or test_loader is None:\n","        train_loader, test_loader, _ = create_rule_switch_dataloaders()\n","    if epochs is None:\n","        epochs = CONFIG['baseline_epochs']\n","    if lr is None:\n","        lr = CONFIG['baseline_lr']\n","\n","    device = next(model.parameters()).device\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    history = {'loss': [], 'accuracy': [], 'perseveration': []}\n","\n","    for epoch in range(epochs):\n","        loss = train_epoch(model, train_loader, optimizer, criterion, device, pruning_manager)\n","\n","        history['loss'].append(loss)\n","\n","        if (epoch + 1) % eval_interval == 0 or epoch == epochs - 1:\n","            metrics = compute_ocd_metrics(model, test_loader, device)\n","            history['accuracy'].append(metrics.accuracy)\n","            history['perseveration'].append(metrics.perseverative_error_rate)\n","\n","            if verbose:\n","                print(f\"    Epoch {epoch+1:3d}/{epochs}: Loss={loss:.4f}, \"\n","                      f\"Acc={metrics.accuracy:.4f}, Persev={metrics.perseverative_error_rate:.4f}\")\n","\n","    return history\n","\n","\n","def train_with_stress_schedule(\n","    model: CSTCNetwork,\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    epochs: int,\n","    lr: float,\n","    initial_stress: float,\n","    final_stress: float = 0.0,\n","    pruning_manager: Optional[CSTCPruningManager] = None,\n","    verbose: bool = False\n",") -> List[float]:\n","    \"\"\"SSRI-like: Prolonged training with gradually reducing internal noise.\"\"\"\n","    device = next(model.parameters()).device\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.CrossEntropyLoss()\n","    losses = []\n","\n","    for epoch in range(epochs):\n","        model.reduce_stress_gradually(epoch, epochs, initial_stress, final_stress)\n","\n","        model.train()\n","        epoch_loss = 0.0\n","        n_batches = 0\n","\n","        for data, labels, _ in train_loader:\n","            data, labels = data.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            logits, _ = model(data)\n","            loss = criterion(logits.view(-1, CONFIG['output_dim']), labels.view(-1))\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","            if pruning_manager:\n","                pruning_manager.apply_masks()\n","\n","            epoch_loss += loss.item()\n","            n_batches += 1\n","\n","        losses.append(epoch_loss / n_batches)\n","\n","        if verbose and (epoch + 1) % 30 == 0:\n","            metrics = compute_ocd_metrics(model, test_loader, device)\n","            print(f\"      SSRI epoch {epoch+1}/{epochs} | stress: {model.stress_level:.3f} | \"\n","                  f\"loss: {losses[-1]:.4f} | acc: {metrics.accuracy:.3f}\")\n","\n","    model.set_stress(final_stress)\n","    return losses\n","\n","\n","# =============================================================================\n","# THREE TREATMENT PROTOCOL FUNCTIONS\n","# =============================================================================\n","\n","def ketamine_treatment_ocd(\n","    model: CSTCNetwork,\n","    pruning_mgr: CSTCPruningManager,\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    regrow_fraction: float = None,\n","    consolidation_epochs: int = None,\n","    verbose: bool = True\n",") -> Dict[str, Any]:\n","    \"\"\"Ketamine-like: Rapid structural synaptogenesis.\"\"\"\n","    if regrow_fraction is None:\n","        regrow_fraction = CONFIG['comparison_ketamine_regrow']\n","    if consolidation_epochs is None:\n","        consolidation_epochs = CONFIG['comparison_ketamine_epochs']\n","\n","    if verbose:\n","        print(f\"      [KETAMINE] regrow_fraction={regrow_fraction:.2f}, consolidation={consolidation_epochs} epochs\")\n","\n","    regrow_stats = pruning_mgr.gradient_guided_regrow(\n","        train_loader,\n","        regrow_fraction=regrow_fraction\n","    )\n","    total_regrown = regrow_stats['connections_regrown']\n","\n","    train(\n","        model, train_loader, test_loader,\n","        epochs=consolidation_epochs,\n","        lr=CONFIG['finetune_lr'],\n","        pruning_manager=pruning_mgr,\n","        verbose=False\n","    )\n","\n","    final_sparsity = pruning_mgr.get_sparsity()\n","\n","    return {\n","        'treatment': 'ketamine',\n","        'mechanism': 'structural',\n","        'regrown': total_regrown,\n","        'regrow_fraction': regrow_fraction,\n","        'consolidation_epochs': consolidation_epochs,\n","        'final_sparsity': final_sparsity\n","    }\n","\n","\n","def ssri_treatment_ocd(\n","    model: CSTCNetwork,\n","    pruning_mgr: CSTCPruningManager,\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    epochs: int = None,\n","    lr: float = None,\n","    initial_stress: float = None,\n","    verbose: bool = True\n",") -> Dict[str, Any]:\n","    \"\"\"SSRI-like: Gradual functional stabilization (fixed structure).\"\"\"\n","    if epochs is None:\n","        epochs = CONFIG['comparison_ssri_epochs']\n","    if lr is None:\n","        lr = CONFIG['comparison_ssri_lr']\n","    if initial_stress is None:\n","        initial_stress = CONFIG['comparison_ssri_initial_stress']\n","\n","    if verbose:\n","        print(f\"      [SSRI] epochs={epochs}, lr={lr:.0e}, initial_stress={initial_stress:.2f}\")\n","\n","    initial_sparsity = pruning_mgr.get_sparsity()\n","\n","    train_with_stress_schedule(\n","        model, train_loader, test_loader,\n","        epochs=epochs,\n","        lr=lr,\n","        initial_stress=initial_stress,\n","        final_stress=0.0,\n","        pruning_manager=pruning_mgr,\n","        verbose=False\n","    )\n","\n","    final_sparsity = pruning_mgr.get_sparsity()\n","\n","    return {\n","        'treatment': 'ssri',\n","        'mechanism': 'functional',\n","        'epochs': epochs,\n","        'lr': lr,\n","        'initial_stress': initial_stress,\n","        'final_stress': model.stress_level,\n","        'initial_sparsity': initial_sparsity,\n","        'final_sparsity': final_sparsity\n","    }\n","\n","\n","def neurosteroid_treatment_ocd(\n","    model: CSTCNetwork,\n","    pruning_mgr: CSTCPruningManager,\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    strength: float = None,\n","    use_tanh: bool = None,\n","    consolidation_epochs: int = None,\n","    verbose: bool = True\n",") -> Dict[str, Any]:\n","    \"\"\"Neurosteroid-like: Rapid tonic inhibition (medication-dependent).\"\"\"\n","    if strength is None:\n","        strength = CONFIG['comparison_neurosteroid_strength']\n","    if use_tanh is None:\n","        use_tanh = CONFIG['comparison_neurosteroid_use_tanh']\n","    if consolidation_epochs is None:\n","        consolidation_epochs = CONFIG['comparison_neurosteroid_epochs']\n","\n","    if verbose:\n","        print(f\"      [NEUROSTEROID] strength={strength:.2f}, use_tanh={use_tanh}, consolidation={consolidation_epochs} epochs\")\n","\n","    initial_sparsity = pruning_mgr.get_sparsity()\n","\n","    model.set_inhibition(strength, use_tanh)\n","\n","    train(\n","        model, train_loader, test_loader,\n","        epochs=consolidation_epochs,\n","        lr=CONFIG['finetune_lr'],\n","        pruning_manager=pruning_mgr,\n","        verbose=False\n","    )\n","\n","    final_sparsity = pruning_mgr.get_sparsity()\n","\n","    return {\n","        'treatment': 'neurosteroid',\n","        'mechanism': 'functional_medication_dependent',\n","        'strength': strength,\n","        'use_tanh': use_tanh,\n","        'consolidation_epochs': consolidation_epochs,\n","        'initial_sparsity': initial_sparsity,\n","        'final_sparsity': final_sparsity\n","    }\n","\n","\n","# =============================================================================\n","# ISO-DOSE PARAMETER SWEEP FUNCTIONS\n","# =============================================================================\n","\n","def run_ketamine_sweep(\n","    base_state: Dict[str, torch.Tensor],\n","    base_masks: Dict[str, torch.Tensor],\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    device: torch.device,\n","    regrow_fractions: List[float] = None\n",") -> List[Dict[str, Any]]:\n","    \"\"\"Sweep ketamine regrow_fraction and measure dose + outcomes.\"\"\"\n","    if regrow_fractions is None:\n","        regrow_fractions = CONFIG['ketamine_regrow_sweep']\n","\n","    results = []\n","\n","    for regrow_frac in regrow_fractions:\n","        model = CSTCNetwork().to(device)\n","        model.load_state_dict(copy.deepcopy(base_state))\n","        mgr = CSTCPruningManager(model)\n","        mgr.masks = copy.deepcopy(base_masks)\n","        mgr.apply_masks()\n","\n","        pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n","\n","        treatment_info = ketamine_treatment_ocd(\n","            model, mgr, train_loader, test_loader,\n","            regrow_fraction=regrow_frac,\n","            verbose=False\n","        )\n","\n","        dose_metrics = compute_all_dose_metrics(pre_state, model)\n","        acute_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","        pre_relapse_persev = acute_metrics.perseverative_error_rate\n","        mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n","        relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","        results.append({\n","            'treatment': 'ketamine',\n","            'param_name': 'regrow_fraction',\n","            'param_value': regrow_frac,\n","            'dose': dose_metrics,\n","            'acute_persev': acute_metrics.perseverative_error_rate,\n","            'acute_flex': acute_metrics.flexibility_index,\n","            'acute_accuracy': acute_metrics.accuracy,\n","            'relapse_persev': relapse_metrics.perseverative_error_rate,\n","            'relapse_delta': relapse_metrics.perseverative_error_rate - pre_relapse_persev,\n","            'treatment_info': treatment_info\n","        })\n","\n","    return results\n","\n","\n","def run_ssri_sweep(\n","    base_state: Dict[str, torch.Tensor],\n","    base_masks: Dict[str, torch.Tensor],\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    device: torch.device,\n","    epochs_list: List[int] = None,\n","    lr_list: List[float] = None\n",") -> List[Dict[str, Any]]:\n","    \"\"\"Sweep SSRI epochs and LR, measure dose + outcomes.\"\"\"\n","    if epochs_list is None:\n","        epochs_list = CONFIG['ssri_epochs_sweep']\n","    if lr_list is None:\n","        lr_list = [CONFIG['comparison_ssri_lr']]\n","\n","    results = []\n","\n","    for epochs in epochs_list:\n","        for lr in lr_list:\n","            model = CSTCNetwork().to(device)\n","            model.load_state_dict(copy.deepcopy(base_state))\n","            mgr = CSTCPruningManager(model)\n","            mgr.masks = copy.deepcopy(base_masks)\n","            mgr.apply_masks()\n","\n","            pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n","\n","            treatment_info = ssri_treatment_ocd(\n","                model, mgr, train_loader, test_loader,\n","                epochs=epochs,\n","                lr=lr,\n","                verbose=False\n","            )\n","\n","            dose_metrics = compute_all_dose_metrics(pre_state, model)\n","            acute_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","            pre_relapse_persev = acute_metrics.perseverative_error_rate\n","            mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n","            relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","            results.append({\n","                'treatment': 'ssri',\n","                'param_name': 'epochs',\n","                'param_value': epochs,\n","                'lr': lr,\n","                'dose': dose_metrics,\n","                'acute_persev': acute_metrics.perseverative_error_rate,\n","                'acute_flex': acute_metrics.flexibility_index,\n","                'acute_accuracy': acute_metrics.accuracy,\n","                'relapse_persev': relapse_metrics.perseverative_error_rate,\n","                'relapse_delta': relapse_metrics.perseverative_error_rate - pre_relapse_persev,\n","                'treatment_info': treatment_info\n","            })\n","\n","    return results\n","\n","\n","def run_neurosteroid_sweep(\n","    base_state: Dict[str, torch.Tensor],\n","    base_masks: Dict[str, torch.Tensor],\n","    train_loader: DataLoader,\n","    test_loader: DataLoader,\n","    device: torch.device,\n","    strength_list: List[float] = None\n",") -> List[Dict[str, Any]]:\n","    \"\"\"Sweep neurosteroid strength, measure dose + outcomes.\"\"\"\n","    if strength_list is None:\n","        strength_list = CONFIG['neurosteroid_strength_sweep']\n","\n","    results = []\n","\n","    for strength in strength_list:\n","        model = CSTCNetwork().to(device)\n","        model.load_state_dict(copy.deepcopy(base_state))\n","        mgr = CSTCPruningManager(model)\n","        mgr.masks = copy.deepcopy(base_masks)\n","        mgr.apply_masks()\n","\n","        pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n","\n","        treatment_info = neurosteroid_treatment_ocd(\n","            model, mgr, train_loader, test_loader,\n","            strength=strength,\n","            verbose=False\n","        )\n","\n","        dose_metrics = compute_all_dose_metrics(pre_state, model)\n","        acute_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","        model.set_inhibition(1.0, False)\n","        off_med_metrics = compute_ocd_metrics(model, test_loader, device)\n","        model.set_inhibition(strength, CONFIG['comparison_neurosteroid_use_tanh'])\n","\n","        pre_relapse_persev = acute_metrics.perseverative_error_rate\n","        mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n","        relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","        results.append({\n","            'treatment': 'neurosteroid',\n","            'param_name': 'strength',\n","            'param_value': strength,\n","            'dose': dose_metrics,\n","            'acute_persev': acute_metrics.perseverative_error_rate,\n","            'acute_flex': acute_metrics.flexibility_index,\n","            'acute_accuracy': acute_metrics.accuracy,\n","            'off_med_persev': off_med_metrics.perseverative_error_rate,\n","            'off_med_reversal': off_med_metrics.perseverative_error_rate - acute_metrics.perseverative_error_rate,\n","            'relapse_persev': relapse_metrics.perseverative_error_rate,\n","            'relapse_delta': relapse_metrics.perseverative_error_rate - pre_relapse_persev,\n","            'treatment_info': treatment_info\n","        })\n","\n","    return results\n","\n","\n","def find_iso_dose_params(\n","    sweep_results: List[Dict[str, Any]],\n","    target_dose: float,\n","    tolerance: float = None\n",") -> Optional[Dict[str, Any]]:\n","    \"\"\"Find parameter configuration closest to target dose.\"\"\"\n","    if tolerance is None:\n","        tolerance = CONFIG['iso_dose_tolerance']\n","\n","    best_match = None\n","    best_diff = float('inf')\n","\n","    for result in sweep_results:\n","        dose = result['dose'].l1_norm\n","        diff = abs(dose - target_dose)\n","        if diff < best_diff:\n","            best_diff = diff\n","            best_match = result\n","\n","    if best_match and best_diff <= tolerance:\n","        return best_match\n","    return best_match\n","\n","\n","# =============================================================================\n","# ISO-DOSE COMPARISON EXPERIMENT\n","# =============================================================================\n","\n","def run_iso_dose_comparison_experiment(\n","    device: torch.device,\n","    seed: int = None,\n","    verbose: bool = True\n",") -> Dict[str, Any]:\n","    \"\"\"\n","    Run iso-dose comparison across all three treatment mechanisms.\n","\n","    Sweeps parameters for each treatment, measures dose (L1 weight change norm),\n","    and compares outcomes at matched dose levels.\n","    \"\"\"\n","    if seed is None:\n","        seed = CONFIG['seed']\n","    set_seed(seed)\n","\n","    print_section_header(\"ISO-DOSE FAIR COMPARISON EXPERIMENT\", char=\"\")\n","    print(f\"\\n  Seed: {seed}\")\n","    print(f\"  Device: {device}\")\n","    print(f\"  Dose metric: L1 weight change norm (normalized per parameter)\")\n","\n","    train_loader, test_loader, _ = create_rule_switch_dataloaders()\n","\n","    # =========================================================================\n","    # PHASE 1: Create shared pruned baseline\n","    # =========================================================================\n","    print_subsection_header(\"PHASE 1: Creating Shared Pruned Baseline\")\n","\n","    base_model = CSTCNetwork().to(device)\n","    print(\"  Training healthy baseline model...\")\n","    train(base_model, train_loader, test_loader, verbose=False)\n","\n","    base_mgr = CSTCPruningManager(base_model)\n","    prune_stats = base_mgr.prune_by_magnitude(sparsity=CONFIG['ocd_prune_sparsity'])\n","\n","    print(f\"  Applied developmental over-pruning: {CONFIG['ocd_prune_sparsity']*100:.0f}%\")\n","    print(f\"  Achieved sparsity: {prune_stats['achieved_sparsity']*100:.1f}%\")\n","\n","    base_state = copy.deepcopy(base_model.state_dict())\n","    base_masks = copy.deepcopy(base_mgr.masks)\n","\n","    untreated_metrics = compute_ocd_metrics(base_model, test_loader, device)\n","    print(f\"\\n  UNTREATED OCD BASELINE:\")\n","    print(f\"    Perseverative Errors: {untreated_metrics.perseverative_error_rate:.4f}\")\n","    print(f\"    Flexibility Index:    {untreated_metrics.flexibility_index:.4f}\")\n","    print(f\"    Accuracy:             {untreated_metrics.accuracy:.4f}\")\n","\n","    results = {\n","        'untreated': {\n","            'persev': untreated_metrics.perseverative_error_rate,\n","            'flex': untreated_metrics.flexibility_index,\n","            'accuracy': untreated_metrics.accuracy,\n","            'sparsity': untreated_metrics.sparsity\n","        },\n","        'sweeps': {},\n","        'iso_dose_comparisons': {}\n","    }\n","\n","    # =========================================================================\n","    # PHASE 2: Parameter Sweeps\n","    # =========================================================================\n","    print_subsection_header(\"PHASE 2: Parameter Sweeps (Measuring Dose-Response)\")\n","\n","    print(\"\\n  [KETAMINE] Sweeping regrow_fraction...\")\n","    ketamine_results = run_ketamine_sweep(\n","        base_state, base_masks, train_loader, test_loader, device\n","    )\n","    results['sweeps']['ketamine'] = ketamine_results\n","    print(f\"    Completed {len(ketamine_results)} configurations\")\n","\n","    print(\"\\n  [SSRI] Sweeping epochs...\")\n","    ssri_results = run_ssri_sweep(\n","        base_state, base_masks, train_loader, test_loader, device\n","    )\n","    results['sweeps']['ssri'] = ssri_results\n","    print(f\"    Completed {len(ssri_results)} configurations\")\n","\n","    print(\"\\n  [NEUROSTEROID] Sweeping strength...\")\n","    neurosteroid_results = run_neurosteroid_sweep(\n","        base_state, base_masks, train_loader, test_loader, device\n","    )\n","    results['sweeps']['neurosteroid'] = neurosteroid_results\n","    print(f\"    Completed {len(neurosteroid_results)} configurations\")\n","\n","    # =========================================================================\n","    # PHASE 3: Dose-Response Analysis\n","    # =========================================================================\n","    print_subsection_header(\"PHASE 3: Dose-Response Curves\")\n","\n","    print(\"\\n  KETAMINE DOSE-RESPONSE:\")\n","    print(f\"  {'regrow_frac':>12} {'L1 Dose':>12} {'Turnover':>12} {'Acute Prsv':>12} {'Relapse ':>12}\")\n","    print(\"  \" + \"-\" * 64)\n","    for r in ketamine_results:\n","        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {r['dose'].synaptic_turnover:>12.4f} \"\n","              f\"{r['acute_persev']:>12.4f} {r['relapse_delta']:>+12.4f}\")\n","\n","    print(\"\\n  SSRI DOSE-RESPONSE:\")\n","    print(f\"  {'epochs':>12} {'L1 Dose':>12} {'Turnover':>12} {'Acute Prsv':>12} {'Relapse ':>12}\")\n","    print(\"  \" + \"-\" * 64)\n","    for r in ssri_results:\n","        print(f\"  {r['param_value']:>12} {r['dose'].l1_norm:>12.6f} {r['dose'].synaptic_turnover:>12.4f} \"\n","              f\"{r['acute_persev']:>12.4f} {r['relapse_delta']:>+12.4f}\")\n","\n","    print(\"\\n  NEUROSTEROID DOSE-RESPONSE:\")\n","    print(f\"  {'strength':>12} {'L1 Dose':>12} {'Turnover':>12} {'Acute Prsv':>12} {'Off-med ':>12} {'Relapse ':>12}\")\n","    print(\"  \" + \"-\" * 76)\n","    for r in neurosteroid_results:\n","        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {r['dose'].synaptic_turnover:>12.4f} \"\n","              f\"{r['acute_persev']:>12.4f} {r['off_med_reversal']:>+12.4f} {r['relapse_delta']:>+12.4f}\")\n","\n","    # =========================================================================\n","    # PHASE 4: Iso-Dose Matching\n","    # =========================================================================\n","    print_subsection_header(\"PHASE 4: Iso-Dose Matched Comparisons\")\n","\n","    all_doses = []\n","    for r in ketamine_results:\n","        all_doses.append(r['dose'].l1_norm)\n","    for r in ssri_results:\n","        all_doses.append(r['dose'].l1_norm)\n","    for r in neurosteroid_results:\n","        all_doses.append(r['dose'].l1_norm)\n","\n","    dose_range = (min(all_doses), max(all_doses))\n","    print(f\"\\n  Observed dose range: {dose_range[0]:.6f} - {dose_range[1]:.6f}\")\n","\n","    target_doses = CONFIG['iso_dose_target_doses']\n","    valid_targets = [d for d in target_doses if dose_range[0] <= d <= dose_range[1]]\n","\n","    if not valid_targets:\n","        dose_percentiles = [25, 50, 75]\n","        valid_targets = [np.percentile(all_doses, p) for p in dose_percentiles]\n","        print(f\"  Using dose percentiles: {[f'{d:.6f}' for d in valid_targets]}\")\n","    else:\n","        print(f\"  Target doses: {valid_targets}\")\n","\n","    for target_dose in valid_targets:\n","        print(f\"\\n  ISO-DOSE TARGET: {target_dose:.6f}\")\n","        print(\"  \" + \"=\" * 70)\n","\n","        ket_match = find_iso_dose_params(ketamine_results, target_dose)\n","        ssri_match = find_iso_dose_params(ssri_results, target_dose)\n","        neuro_match = find_iso_dose_params(neurosteroid_results, target_dose)\n","\n","        iso_comparison = {\n","            'target_dose': target_dose,\n","            'ketamine': ket_match,\n","            'ssri': ssri_match,\n","            'neurosteroid': neuro_match\n","        }\n","        results['iso_dose_comparisons'][target_dose] = iso_comparison\n","\n","        print(f\"\\n  {'Treatment':<15} {'Param':<15} {'Actual Dose':>12} {'Acute Prsv':>12} {'Relapse ':>12} {'Efficiency':>12}\")\n","        print(\"  \" + \"-\" * 80)\n","\n","        for name, match in [('Ketamine', ket_match), ('SSRI', ssri_match), ('Neurosteroid', neuro_match)]:\n","            if match:\n","                param_str = f\"{match['param_name']}={match['param_value']}\"\n","                actual_dose = match['dose'].l1_norm\n","                acute_p = match['acute_persev']\n","                relapse_d = match['relapse_delta']\n","\n","                persev_reduction = untreated_metrics.perseverative_error_rate - acute_p\n","                efficiency = persev_reduction / (actual_dose + 1e-8)\n","\n","                print(f\"  {name:<15} {param_str:<15} {actual_dose:>12.6f} {acute_p:>12.4f} {relapse_d:>+12.4f} {efficiency:>12.2f}\")\n","            else:\n","                print(f\"  {name:<15} {'N/A':<15} {'N/A':>12} {'N/A':>12} {'N/A':>12} {'N/A':>12}\")\n","\n","    # =========================================================================\n","    # PHASE 5: Efficiency Analysis\n","    # =========================================================================\n","    print_subsection_header(\"PHASE 5: Treatment Efficiency Analysis\")\n","\n","    print(\"\\n  EFFICIENCY = (Perseveration Reduction) / (L1 Dose)\")\n","    print(\"  Higher efficiency = better outcome per unit of network change\")\n","\n","    print(\"\\n  KETAMINE EFFICIENCY:\")\n","    print(f\"  {'regrow_frac':>12} {'Dose':>12} {'Prsv Reduc':>12} {'Efficiency':>12}\")\n","    print(\"  \" + \"-\" * 52)\n","    for r in ketamine_results:\n","        reduction = untreated_metrics.perseverative_error_rate - r['acute_persev']\n","        efficiency = reduction / (r['dose'].l1_norm + 1e-8)\n","        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {reduction:>12.4f} {efficiency:>12.2f}\")\n","\n","    print(\"\\n  SSRI EFFICIENCY:\")\n","    print(f\"  {'epochs':>12} {'Dose':>12} {'Prsv Reduc':>12} {'Efficiency':>12}\")\n","    print(\"  \" + \"-\" * 52)\n","    for r in ssri_results:\n","        reduction = untreated_metrics.perseverative_error_rate - r['acute_persev']\n","        efficiency = reduction / (r['dose'].l1_norm + 1e-8)\n","        print(f\"  {r['param_value']:>12} {r['dose'].l1_norm:>12.6f} {reduction:>12.4f} {efficiency:>12.2f}\")\n","\n","    print(\"\\n  NEUROSTEROID EFFICIENCY:\")\n","    print(f\"  {'strength':>12} {'Dose':>12} {'Prsv Reduc':>12} {'Efficiency':>12}\")\n","    print(\"  \" + \"-\" * 52)\n","    for r in neurosteroid_results:\n","        reduction = untreated_metrics.perseverative_error_rate - r['acute_persev']\n","        efficiency = reduction / (r['dose'].l1_norm + 1e-8)\n","        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {reduction:>12.4f} {efficiency:>12.2f}\")\n","\n","    # =========================================================================\n","    # PHASE 6: Summary Statistics\n","    # =========================================================================\n","    print_subsection_header(\"PHASE 6: Summary Statistics\")\n","\n","    def compute_sweep_stats(sweep_results):\n","        doses = [r['dose'].l1_norm for r in sweep_results]\n","        turnovers = [r['dose'].synaptic_turnover for r in sweep_results]\n","        acute_persevs = [r['acute_persev'] for r in sweep_results]\n","        relapse_deltas = [r['relapse_delta'] for r in sweep_results]\n","\n","        reductions = [untreated_metrics.perseverative_error_rate - p for p in acute_persevs]\n","        efficiencies = [r / (d + 1e-8) for r, d in zip(reductions, doses)]\n","\n","        return {\n","            'dose_range': (min(doses), max(doses)),\n","            'turnover_range': (min(turnovers), max(turnovers)),\n","            'best_acute_persev': min(acute_persevs),\n","            'best_relapse_delta': min(relapse_deltas),\n","            'max_efficiency': max(efficiencies),\n","            'mean_efficiency': np.mean(efficiencies)\n","        }\n","\n","    ket_stats = compute_sweep_stats(ketamine_results)\n","    ssri_stats = compute_sweep_stats(ssri_results)\n","    neuro_stats = compute_sweep_stats(neurosteroid_results)\n","\n","    print(\"\\n  TREATMENT SUMMARY:\")\n","    print(f\"  {'Metric':<25} {'Ketamine':>15} {'SSRI':>15} {'Neurosteroid':>15}\")\n","    print(\"  \" + \"-\" * 75)\n","    print(f\"  {'Dose Range (L1)':<25} {ket_stats['dose_range'][0]:.4f}-{ket_stats['dose_range'][1]:.4f}\"\n","          f\"   {ssri_stats['dose_range'][0]:.4f}-{ssri_stats['dose_range'][1]:.4f}\"\n","          f\"   {neuro_stats['dose_range'][0]:.4f}-{neuro_stats['dose_range'][1]:.4f}\")\n","    print(f\"  {'Best Acute Persev':<25} {ket_stats['best_acute_persev']:>15.4f} {ssri_stats['best_acute_persev']:>15.4f} {neuro_stats['best_acute_persev']:>15.4f}\")\n","    print(f\"  {'Best Relapse ':<25} {ket_stats['best_relapse_delta']:>+15.4f} {ssri_stats['best_relapse_delta']:>+15.4f} {neuro_stats['best_relapse_delta']:>+15.4f}\")\n","    print(f\"  {'Max Efficiency':<25} {ket_stats['max_efficiency']:>15.2f} {ssri_stats['max_efficiency']:>15.2f} {neuro_stats['max_efficiency']:>15.2f}\")\n","    print(f\"  {'Mean Efficiency':<25} {ket_stats['mean_efficiency']:>15.2f} {ssri_stats['mean_efficiency']:>15.2f} {neuro_stats['mean_efficiency']:>15.2f}\")\n","\n","    results['summary'] = {\n","        'ketamine': ket_stats,\n","        'ssri': ssri_stats,\n","        'neurosteroid': neuro_stats\n","    }\n","\n","    # =========================================================================\n","    # PHASE 7: Detailed Results Table\n","    # =========================================================================\n","    print_section_header(\"DETAILED ISO-DOSE COMPARISON RESULTS\", char=\"\")\n","\n","    for target_dose, comparison in results['iso_dose_comparisons'].items():\n","        print(f\"\\n  TARGET DOSE: {target_dose:.6f}\")\n","        print(\"  \" + \"=\" * 90)\n","\n","        print(f\"\\n  {'Treatment':<15} {'Parameter':<20} {'Dose L1':>10} {'Turnover':>10} {'Sparsity':>10} \"\n","              f\"{'Acute Prsv':>12} {'Relapse ':>12}\")\n","        print(\"  \" + \"-\" * 90)\n","\n","        for treatment_name in ['ketamine', 'ssri', 'neurosteroid']:\n","            match = comparison.get(treatment_name)\n","            if match:\n","                param_str = f\"{match['param_name']}={match['param_value']}\"\n","                d = match['dose']\n","                print(f\"  {treatment_name.capitalize():<15} {param_str:<20} {d.l1_norm:>10.6f} {d.synaptic_turnover:>10.4f} \"\n","                      f\"{d.sparsity_change:>10.4f} {match['acute_persev']:>12.4f} {match['relapse_delta']:>+12.4f}\")\n","\n","        print(\"\\n  OUTCOME COMPARISON AT THIS DOSE LEVEL:\")\n","\n","        treatments_at_dose = []\n","        for t_name in ['ketamine', 'ssri', 'neurosteroid']:\n","            m = comparison.get(t_name)\n","            if m:\n","                treatments_at_dose.append((t_name, m['acute_persev'], m['relapse_delta']))\n","\n","        if treatments_at_dose:\n","            best_acute = min(treatments_at_dose, key=lambda x: x[1])\n","            best_relapse = min(treatments_at_dose, key=lambda x: x[2])\n","\n","            print(f\"    Best acute perseveration: {best_acute[0].capitalize()} ({best_acute[1]:.4f})\")\n","            print(f\"    Best relapse resistance:  {best_relapse[0].capitalize()} ( = {best_relapse[2]:+.4f})\")\n","\n","            if best_acute[0] == best_relapse[0]:\n","                print(f\"    >> {best_acute[0].upper()} dominates at this dose level\")\n","            else:\n","                print(f\"    >> Trade-off: {best_acute[0].capitalize()} for acute, {best_relapse[0].capitalize()} for durability\")\n","\n","    # =========================================================================\n","    # FINAL CONCLUSIONS\n","    # =========================================================================\n","    print_section_header(\"ISO-DOSE EXPERIMENT CONCLUSIONS\", char=\"\")\n","\n","    print(\"\"\"\n","  ISO-DOSE COMPARISON FINDINGS:\n","\n","  1. DOSE QUANTIFICATION:\n","     - L1 weight change norm provides mechanism-agnostic dose measurement\n","     - Ketamine produces highest dose (structural regrowth)\n","     - SSRI produces moderate dose (gradual weight refinement)\n","     - Neurosteroid produces lowest dose (minimal weight changes, runtime modulation)\n","\n","  2. EFFICIENCY ANALYSIS:\n","     - Efficiency = outcome improvement per unit dose\n","     - Reveals which mechanism achieves most benefit with least network alteration\n","     - Critical for understanding treatment optimization\n","\n","  3. ISO-DOSE MATCHING:\n","     - At matched dose levels, treatments can be fairly compared\n","     - Removes bias from arbitrary hyperparameter scaling\n","     - Reveals inherent mechanism advantages vs parameter-driven effects\n","\n","  4. CLINICAL IMPLICATIONS:\n","     - High-efficiency treatments may be preferred when minimizing side effects\n","     - Low-dose/high-effect treatments may have better safety profiles\n","     - Dose-response curves guide titration strategies\n","    \"\"\")\n","\n","    return results\n","\n","\n","# =============================================================================\n","# ORIGINAL MULTI-MECHANISM COMPARISON (PRESERVED)\n","# =============================================================================\n","\n","def run_multi_mechanism_ocd_experiment(\n","    device: torch.device,\n","    seed: int = None,\n","    verbose: bool = True\n",") -> Dict[str, Any]:\n","    \"\"\"Compare three antidepressant mechanisms in OCD pruning framework.\"\"\"\n","    if seed is None:\n","        seed = CONFIG['seed']\n","    set_seed(seed)\n","\n","    print_section_header(\"MULTI-MECHANISM ANTIDEPRESSANT COMPARISON\", char=\"\")\n","    print(f\"\\n  Comparing treatment mechanisms in OCD model (Seed: {seed})\")\n","\n","    train_loader, test_loader, _ = create_rule_switch_dataloaders()\n","\n","    print_subsection_header(\"PHASE 1: Creating Shared Pruned Baseline\")\n","\n","    base_model = CSTCNetwork().to(device)\n","    print(\"  Training healthy baseline model...\")\n","    train(base_model, train_loader, test_loader, verbose=False)\n","\n","    base_mgr = CSTCPruningManager(base_model)\n","    prune_stats = base_mgr.prune_by_magnitude(sparsity=CONFIG['ocd_prune_sparsity'])\n","\n","    print(f\"  Applied developmental over-pruning: {CONFIG['ocd_prune_sparsity']*100:.0f}%\")\n","    print(f\"  Achieved sparsity: {prune_stats['achieved_sparsity']*100:.1f}%\")\n","\n","    base_state = copy.deepcopy(base_model.state_dict())\n","    base_masks = copy.deepcopy(base_mgr.masks)\n","\n","    results = {}\n","\n","    print_subsection_header(\"PHASE 2: Untreated Baseline Evaluation\")\n","\n","    untreated_metrics = compute_ocd_metrics(base_model, test_loader, device)\n","    results['untreated'] = {\n","        'sparsity': untreated_metrics.sparsity,\n","        'accuracy': untreated_metrics.accuracy,\n","        'persev': untreated_metrics.perseverative_error_rate,\n","        'switch_cost': untreated_metrics.switch_cost,\n","        'flex_index': untreated_metrics.flexibility_index,\n","        'repetition_rate': untreated_metrics.repetition_rate,\n","        'trials_to_recover': untreated_metrics.trials_to_recover\n","    }\n","\n","    print(f\"  UNTREATED OCD STATE:\")\n","    print(f\"    Sparsity:              {untreated_metrics.sparsity*100:.1f}%\")\n","    print(f\"    Accuracy:              {untreated_metrics.accuracy:.4f}\")\n","    print(f\"    Perseverative Errors:  {untreated_metrics.perseverative_error_rate:.4f}\")\n","    print(f\"    Flexibility Index:     {untreated_metrics.flexibility_index:.4f}\")\n","\n","    def clone_baseline():\n","        model = CSTCNetwork().to(device)\n","        model.load_state_dict(copy.deepcopy(base_state))\n","        mgr = CSTCPruningManager(model)\n","        mgr.masks = copy.deepcopy(base_masks)\n","        mgr.apply_masks()\n","        return model, mgr\n","\n","    treatments = ['ketamine', 'ssri', 'neurosteroid']\n","\n","    for treatment in treatments:\n","        print_subsection_header(f\"PHASE 3: {treatment.upper()} Treatment\")\n","\n","        model, mgr = clone_baseline()\n","\n","        pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n","\n","        if treatment == 'ketamine':\n","            treatment_info = ketamine_treatment_ocd(\n","                model, mgr, train_loader, test_loader, verbose=verbose\n","            )\n","        elif treatment == 'ssri':\n","            treatment_info = ssri_treatment_ocd(\n","                model, mgr, train_loader, test_loader, verbose=verbose\n","            )\n","        elif treatment == 'neurosteroid':\n","            treatment_info = neurosteroid_treatment_ocd(\n","                model, mgr, train_loader, test_loader, verbose=verbose\n","            )\n","\n","        dose_metrics = compute_all_dose_metrics(pre_state, model)\n","\n","        acute_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","        off_med_metrics = None\n","        if treatment == 'neurosteroid':\n","            model.set_inhibition(1.0, False)\n","            off_med_metrics = compute_ocd_metrics(model, test_loader, device)\n","            model.set_inhibition(\n","                CONFIG['comparison_neurosteroid_strength'],\n","                CONFIG['comparison_neurosteroid_use_tanh']\n","            )\n","\n","        pre_relapse_persev = acute_metrics.perseverative_error_rate\n","        pre_relapse_flex = acute_metrics.flexibility_index\n","        pre_relapse_acc = acute_metrics.accuracy\n","\n","        mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n","\n","        relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n","\n","        relapse_delta_persev = relapse_metrics.perseverative_error_rate - pre_relapse_persev\n","        relapse_delta_flex = pre_relapse_flex - relapse_metrics.flexibility_index\n","        relapse_delta_acc = pre_relapse_acc - relapse_metrics.accuracy\n","\n","        results[treatment] = {\n","            'treatment_info': treatment_info,\n","            'dose_metrics': {\n","                'l1_norm': dose_metrics.l1_norm,\n","                'l2_norm': dose_metrics.l2_norm,\n","                'synaptic_turnover': dose_metrics.synaptic_turnover,\n","                'sparsity_change': dose_metrics.sparsity_change\n","            },\n","            'acute_sparsity': acute_metrics.sparsity,\n","            'acute_accuracy': acute_metrics.accuracy,\n","            'acute_persev': acute_metrics.perseverative_error_rate,\n","            'acute_flex': acute_metrics.flexibility_index,\n","            'acute_repetition': acute_metrics.repetition_rate,\n","            'acute_switch_cost': acute_metrics.switch_cost,\n","            'acute_recovery': acute_metrics.trials_to_recover,\n","            'improvement_persev': untreated_metrics.perseverative_error_rate - acute_metrics.perseverative_error_rate,\n","            'improvement_flex': acute_metrics.flexibility_index - untreated_metrics.flexibility_index,\n","            'improvement_acc': acute_metrics.accuracy - untreated_metrics.accuracy,\n","            'relapse_sparsity': relapse_metrics.sparsity,\n","            'relapse_persev': relapse_metrics.perseverative_error_rate,\n","            'relapse_flex': relapse_metrics.flexibility_index,\n","            'relapse_delta_persev': relapse_delta_persev,\n","            'relapse_delta_flex': relapse_delta_flex,\n","            'relapse_delta_acc': relapse_delta_acc,\n","            'off_med_persev': off_med_metrics.perseverative_error_rate if off_med_metrics else None,\n","            'off_med_flex': off_med_metrics.flexibility_index if off_med_metrics else None,\n","            'off_med_acc': off_med_metrics.accuracy if off_med_metrics else None,\n","        }\n","\n","        print(f\"\\n    DOSE METRICS:\")\n","        print(f\"      L1 Weight Change:    {dose_metrics.l1_norm:.6f}\")\n","        print(f\"      L2 Weight Change:    {dose_metrics.l2_norm:.6f}\")\n","        print(f\"      Synaptic Turnover:   {dose_metrics.synaptic_turnover:.4f}\")\n","        print(f\"      Sparsity Change:     {dose_metrics.sparsity_change:.4f}\")\n","\n","        print(f\"\\n    ACUTE EFFECTS:\")\n","        print(f\"      Sparsity:            {acute_metrics.sparsity*100:.1f}%\")\n","        print(f\"      Accuracy:            {acute_metrics.accuracy:.4f} ( = {results[treatment]['improvement_acc']:+.4f})\")\n","        print(f\"      Perseveration:       {acute_metrics.perseverative_error_rate:.4f} ( = {-results[treatment]['improvement_persev']:+.4f})\")\n","        print(f\"      Flexibility:         {acute_metrics.flexibility_index:.4f} ( = {results[treatment]['improvement_flex']:+.4f})\")\n","\n","        efficiency = results[treatment]['improvement_persev'] / (dose_metrics.l1_norm + 1e-8)\n","        print(f\"      Efficiency:          {efficiency:.2f} (persev reduction / dose)\")\n","\n","        if off_med_metrics:\n","            print(f\"\\n    OFF-MEDICATION TEST:\")\n","            print(f\"      Perseveration:       {off_med_metrics.perseverative_error_rate:.4f}\")\n","            off_med_delta = off_med_metrics.perseverative_error_rate - acute_metrics.perseverative_error_rate\n","            print(f\"      Reversal:            {off_med_delta:+.4f} perseveration increase\")\n","\n","        print(f\"\\n    RELAPSE SIMULATION ({CONFIG['relapse_prune_fraction']*100:.0f}% secondary pruning):\")\n","        print(f\"      Sparsity:            {relapse_metrics.sparsity*100:.1f}%\")\n","        print(f\"      Perseveration:       {relapse_metrics.perseverative_error_rate:.4f} ( = {relapse_delta_persev:+.4f})\")\n","        print(f\"      Flexibility:         {relapse_metrics.flexibility_index:.4f} ( = {-relapse_delta_flex:+.4f})\")\n","\n","    print_section_header(\"COMPREHENSIVE TREATMENT COMPARISON\", char=\"\")\n","\n","    print(\"\\n  DOSE COMPARISON:\")\n","    print(f\"  {'Treatment':<15} {'L1 Dose':>12} {'L2 Dose':>12} {'Turnover':>12} {'Sparsity':>12}\")\n","    print(\"  \" + \"-\" * 65)\n","    for treatment in treatments:\n","        dm = results[treatment]['dose_metrics']\n","        print(f\"  {treatment.capitalize():<15} {dm['l1_norm']:>12.6f} {dm['l2_norm']:>12.6f} \"\n","              f\"{dm['synaptic_turnover']:>12.4f} {dm['sparsity_change']:>12.4f}\")\n","\n","    print(\"\\n  ACUTE EFFECTS:\")\n","    print(f\"  {'Treatment':<15} {'Sparsity':>10} {'Accuracy':>10} {'Persev':>10} {'Flex':>10} {'Efficiency':>12}\")\n","    print(\"  \" + \"-\" * 70)\n","    print(f\"  {'Untreated':<15} {results['untreated']['sparsity']*100:>9.1f}% \"\n","          f\"{results['untreated']['accuracy']:>10.4f} {results['untreated']['persev']:>10.4f} \"\n","          f\"{results['untreated']['flex_index']:>10.4f} {'N/A':>12}\")\n","\n","    for treatment in treatments:\n","        r = results[treatment]\n","        efficiency = r['improvement_persev'] / (r['dose_metrics']['l1_norm'] + 1e-8)\n","        print(f\"  {treatment.capitalize():<15} {r['acute_sparsity']*100:>9.1f}% \"\n","              f\"{r['acute_accuracy']:>10.4f} {r['acute_persev']:>10.4f} \"\n","              f\"{r['acute_flex']:>10.4f} {efficiency:>12.2f}\")\n","\n","    print(\"\\n  RELAPSE VULNERABILITY:\")\n","    print(f\"  {'Treatment':<15} {'Persev':>12} {'Flexibility':>12} {'Interpretation':<25}\")\n","    print(\"  \" + \"-\" * 70)\n","\n","    for treatment in treatments:\n","        r = results[treatment]\n","        if r['relapse_delta_persev'] < 0.02:\n","            interp = \"Relapse resistant\"\n","        elif r['relapse_delta_persev'] < 0.05:\n","            interp = \"Moderate relapse\"\n","        else:\n","            interp = \"High relapse risk\"\n","\n","        print(f\"  {treatment.capitalize():<15} {r['relapse_delta_persev']:>+12.4f} \"\n","              f\"{-r['relapse_delta_flex']:>+12.4f} {interp:<25}\")\n","\n","    return results\n","\n","\n","# =============================================================================\n","# MAIN ENTRY POINT\n","# =============================================================================\n","\n","def main():\n","    \"\"\"Run full OCD hypothesis validation suite with iso-dose comparison.\"\"\"\n","    print(\"\\n\" + \"\" * 80)\n","    print(\"\" + \" \" * 78 + \"\")\n","    print(\"\" + \"COMPUTATIONAL MODEL: OCD SYNAPTIC PRUNING HYPOTHESIS\".center(78) + \"\")\n","    print(\"\" + \"WITH ISO-DOSE FAIR COMPARISON PIPELINE\".center(78) + \"\")\n","    print(\"\" + \" \" * 78 + \"\")\n","    print(\"\" * 80)\n","\n","    print(f\"\\n  PyTorch Version: {torch.__version__}\")\n","    print(f\"  Device: {DEVICE}\")\n","    print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n","\n","    set_seed(CONFIG['seed'])\n","\n","    print(\"\\n  Running Multi-Mechanism Comparison (with dose metrics)...\")\n","    multi_results = run_multi_mechanism_ocd_experiment(DEVICE, verbose=True)\n","\n","    print(\"\\n  Running Iso-Dose Comparison Experiment...\")\n","    iso_dose_results = run_iso_dose_comparison_experiment(DEVICE, verbose=True)\n","\n","    print(\"\\n\" + \"\" * 80)\n","    print(\"\" + \"EXPERIMENT COMPLETE\".center(78) + \"\")\n","    print(\"\" * 80)\n","\n","    return {\n","        'multi_mechanism': multi_results,\n","        'iso_dose': iso_dose_results\n","    }\n","\n","\n","if __name__ == \"__main__\":\n","    results = main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMVxs7To9p5o","executionInfo":{"status":"ok","timestamp":1769062857672,"user_tz":-480,"elapsed":147452,"user":{"displayName":"Ngo Cheung","userId":"02091267041339546959"}},"outputId":"dea5c05f-0148-45d4-b859-e86acf409132"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","                                                                              \n","             COMPUTATIONAL MODEL: OCD SYNAPTIC PRUNING HYPOTHESIS             \n","                    WITH ISO-DOSE FAIR COMPARISON PIPELINE                    \n","                                                                              \n","\n","\n","  PyTorch Version: 2.9.0+cu126\n","  Device: cuda\n","  CUDA Available: True\n","\n","  Running Multi-Mechanism Comparison (with dose metrics)...\n","\n","\n","                   MULTI-MECHANISM ANTIDEPRESSANT COMPARISON                    \n","\n","\n","  Comparing treatment mechanisms in OCD model (Seed: 42)\n","\n","------------------------------------------------------------\n","  PHASE 1: Creating Shared Pruned Baseline\n","------------------------------------------------------------\n","  Training healthy baseline model...\n","  Applied developmental over-pruning: 95%\n","  Achieved sparsity: 95.0%\n","\n","------------------------------------------------------------\n","  PHASE 2: Untreated Baseline Evaluation\n","------------------------------------------------------------\n","  UNTREATED OCD STATE:\n","    Sparsity:              95.0%\n","    Accuracy:              0.4230\n","    Perseverative Errors:  0.7314\n","    Flexibility Index:     0.9724\n","\n","------------------------------------------------------------\n","  PHASE 3: KETAMINE Treatment\n","------------------------------------------------------------\n","      [KETAMINE] regrow_fraction=0.60, consolidation=10 epochs\n","\n","    DOSE METRICS:\n","      L1 Weight Change:    0.010953\n","      L2 Weight Change:    0.000066\n","      Synaptic Turnover:   0.5868\n","      Sparsity Change:     0.5678\n","\n","    ACUTE EFFECTS:\n","      Sparsity:            38.2%\n","      Accuracy:            0.7508 ( = +0.3278)\n","      Perseveration:       0.2329 ( = -0.4985)\n","      Flexibility:         0.9835 ( = +0.0111)\n","      Efficiency:          45.51 (persev reduction / dose)\n","\n","    RELAPSE SIMULATION (40% secondary pruning):\n","      Sparsity:            62.9%\n","      Perseveration:       0.3204 ( = +0.0874)\n","      Flexibility:         0.9748 ( = -0.0087)\n","\n","------------------------------------------------------------\n","  PHASE 3: SSRI Treatment\n","------------------------------------------------------------\n","      [SSRI] epochs=120, lr=1e-05, initial_stress=0.40\n","\n","    DOSE METRICS:\n","      L1 Weight Change:    0.000688\n","      L2 Weight Change:    0.000013\n","      Synaptic Turnover:   0.0011\n","      Sparsity Change:     0.0000\n","\n","    ACUTE EFFECTS:\n","      Sparsity:            95.0%\n","      Accuracy:            0.5322 ( = +0.1091)\n","      Perseveration:       0.6871 ( = -0.0443)\n","      Flexibility:         0.9994 ( = +0.0270)\n","      Efficiency:          64.35 (persev reduction / dose)\n","\n","    RELAPSE SIMULATION (40% secondary pruning):\n","      Sparsity:            97.0%\n","      Perseveration:       0.8482 ( = +0.1612)\n","      Flexibility:         0.9710 ( = -0.0284)\n","\n","------------------------------------------------------------\n","  PHASE 3: NEUROSTEROID Treatment\n","------------------------------------------------------------\n","      [NEUROSTEROID] strength=0.65, use_tanh=True, consolidation=8 epochs\n","\n","    DOSE METRICS:\n","      L1 Weight Change:    0.002128\n","      L2 Weight Change:    0.000043\n","      Synaptic Turnover:   0.0355\n","      Sparsity Change:     0.0000\n","\n","    ACUTE EFFECTS:\n","      Sparsity:            95.0%\n","      Accuracy:            0.5896 ( = +0.1666)\n","      Perseveration:       0.6422 ( = -0.0892)\n","      Flexibility:         0.9945 ( = +0.0221)\n","      Efficiency:          41.91 (persev reduction / dose)\n","\n","    OFF-MEDICATION TEST:\n","      Perseveration:       0.6261\n","      Reversal:            -0.0161 perseveration increase\n","\n","    RELAPSE SIMULATION (40% secondary pruning):\n","      Sparsity:            97.0%\n","      Perseveration:       0.8108 ( = +0.1686)\n","      Flexibility:         0.9752 ( = -0.0193)\n","\n","\n","                       COMPREHENSIVE TREATMENT COMPARISON                       \n","\n","\n","  DOSE COMPARISON:\n","  Treatment            L1 Dose      L2 Dose     Turnover    Sparsity\n","  -----------------------------------------------------------------\n","  Ketamine            0.010953     0.000066       0.5868       0.5678\n","  Ssri                0.000688     0.000013       0.0011       0.0000\n","  Neurosteroid        0.002128     0.000043       0.0355       0.0000\n","\n","  ACUTE EFFECTS:\n","  Treatment         Sparsity   Accuracy     Persev       Flex   Efficiency\n","  ----------------------------------------------------------------------\n","  Untreated            95.0%     0.4230     0.7314     0.9724          N/A\n","  Ketamine             38.2%     0.7508     0.2329     0.9835        45.51\n","  Ssri                 95.0%     0.5322     0.6871     0.9994        64.35\n","  Neurosteroid         95.0%     0.5896     0.6422     0.9945        41.91\n","\n","  RELAPSE VULNERABILITY:\n","  Treatment            Persev Flexibility Interpretation           \n","  ----------------------------------------------------------------------\n","  Ketamine             +0.0874      -0.0087 High relapse risk        \n","  Ssri                 +0.1612      -0.0284 High relapse risk        \n","  Neurosteroid         +0.1686      -0.0193 High relapse risk        \n","\n","  Running Iso-Dose Comparison Experiment...\n","\n","\n","                      ISO-DOSE FAIR COMPARISON EXPERIMENT                       \n","\n","\n","  Seed: 42\n","  Device: cuda\n","  Dose metric: L1 weight change norm (normalized per parameter)\n","\n","------------------------------------------------------------\n","  PHASE 1: Creating Shared Pruned Baseline\n","------------------------------------------------------------\n","  Training healthy baseline model...\n","  Applied developmental over-pruning: 95%\n","  Achieved sparsity: 95.0%\n","\n","  UNTREATED OCD BASELINE:\n","    Perseverative Errors: 0.7314\n","    Flexibility Index:    0.9724\n","    Accuracy:             0.4230\n","\n","------------------------------------------------------------\n","  PHASE 2: Parameter Sweeps (Measuring Dose-Response)\n","------------------------------------------------------------\n","\n","  [KETAMINE] Sweeping regrow_fraction...\n","    Completed 8 configurations\n","\n","  [SSRI] Sweeping epochs...\n","    Completed 8 configurations\n","\n","  [NEUROSTEROID] Sweeping strength...\n","    Completed 8 configurations\n","\n","------------------------------------------------------------\n","  PHASE 3: Dose-Response Curves\n","------------------------------------------------------------\n","\n","  KETAMINE DOSE-RESPONSE:\n","   regrow_frac      L1 Dose     Turnover   Acute Prsv    Relapse \n","  ----------------------------------------------------------------\n","          0.10     0.004506       0.1254       0.2627      +0.0508\n","          0.20     0.006099       0.2171       0.2347      +0.0175\n","          0.30     0.007355       0.3080       0.2344      +0.0438\n","          0.40     0.008419       0.3996       0.2344      +0.0858\n","          0.50     0.009600       0.4926       0.2333      +0.0983\n","          0.60     0.010939       0.5867       0.2333      +0.1328\n","          0.70     0.012233       0.6802       0.2336      +0.0847\n","          0.80     0.013811       0.7746       0.2336      +0.0790\n","\n","  SSRI DOSE-RESPONSE:\n","        epochs      L1 Dose     Turnover   Acute Prsv    Relapse \n","  ----------------------------------------------------------------\n","            20     0.000151       0.0000       0.7308      -0.0135\n","            40     0.000293       0.0000       0.7157      +0.0003\n","            60     0.000414       0.0000       0.7009      +0.0803\n","            80     0.000519       0.0000       0.6957      +0.1329\n","           100     0.000611       0.0000       0.6944      +0.1404\n","           120     0.000689       0.0010       0.6864      +0.1619\n","           160     0.000818       0.0068       0.6741      +0.1627\n","           200     0.000944       0.0131       0.6619      +0.1662\n","\n","  NEUROSTEROID DOSE-RESPONSE:\n","      strength      L1 Dose     Turnover   Acute Prsv    Off-med     Relapse \n","  ----------------------------------------------------------------------------\n","          0.50     0.002474       0.0405       0.6563      -0.0276      +0.1492\n","          0.55     0.002354       0.0390       0.6558      -0.0273      +0.1426\n","          0.60     0.002236       0.0373       0.6517      -0.0263      +0.1505\n","          0.65     0.002117       0.0354       0.6428      -0.0172      +0.1700\n","          0.70     0.002026       0.0339       0.6373      -0.0175      +0.1751\n","          0.75     0.001949       0.0326       0.6359      -0.0121      +0.1734\n","          0.80     0.001871       0.0310       0.6343      -0.0143      +0.1797\n","          0.85     0.001802       0.0301       0.6298      -0.0099      +0.1798\n","\n","------------------------------------------------------------\n","  PHASE 4: Iso-Dose Matched Comparisons\n","------------------------------------------------------------\n","\n","  Observed dose range: 0.000151 - 0.013811\n","  Target doses: [0.005, 0.01]\n","\n","  ISO-DOSE TARGET: 0.005000\n","  ======================================================================\n","\n","  Treatment       Param            Actual Dose   Acute Prsv    Relapse    Efficiency\n","  --------------------------------------------------------------------------------\n","  Ketamine        regrow_fraction=0.1     0.004506       0.2627      +0.0508       104.01\n","  SSRI            epochs=200          0.000944       0.6619      +0.1662        73.68\n","  Neurosteroid    strength=0.5        0.002474       0.6563      +0.1492        30.35\n","\n","  ISO-DOSE TARGET: 0.010000\n","  ======================================================================\n","\n","  Treatment       Param            Actual Dose   Acute Prsv    Relapse    Efficiency\n","  --------------------------------------------------------------------------------\n","  Ketamine        regrow_fraction=0.5     0.009600       0.2333      +0.0983        51.88\n","  SSRI            epochs=200          0.000944       0.6619      +0.1662        73.68\n","  Neurosteroid    strength=0.5        0.002474       0.6563      +0.1492        30.35\n","\n","------------------------------------------------------------\n","  PHASE 5: Treatment Efficiency Analysis\n","------------------------------------------------------------\n","\n","  EFFICIENCY = (Perseveration Reduction) / (L1 Dose)\n","  Higher efficiency = better outcome per unit of network change\n","\n","  KETAMINE EFFICIENCY:\n","   regrow_frac         Dose   Prsv Reduc   Efficiency\n","  ----------------------------------------------------\n","          0.10     0.004506       0.4687       104.01\n","          0.20     0.006099       0.4967        81.44\n","          0.30     0.007355       0.4970        67.58\n","          0.40     0.008419       0.4970        59.04\n","          0.50     0.009600       0.4981        51.88\n","          0.60     0.010939       0.4981        45.53\n","          0.70     0.012233       0.4978        40.69\n","          0.80     0.013811       0.4978        36.04\n","\n","  SSRI EFFICIENCY:\n","        epochs         Dose   Prsv Reduc   Efficiency\n","  ----------------------------------------------------\n","            20     0.000151       0.0006         3.68\n","            40     0.000293       0.0157        53.63\n","            60     0.000414       0.0305        73.64\n","            80     0.000519       0.0357        68.85\n","           100     0.000611       0.0370        60.65\n","           120     0.000689       0.0450        65.38\n","           160     0.000818       0.0573        70.05\n","           200     0.000944       0.0695        73.68\n","\n","  NEUROSTEROID EFFICIENCY:\n","      strength         Dose   Prsv Reduc   Efficiency\n","  ----------------------------------------------------\n","          0.50     0.002474       0.0751        30.35\n","          0.55     0.002354       0.0756        32.13\n","          0.60     0.002236       0.0796        35.62\n","          0.65     0.002117       0.0886        41.84\n","          0.70     0.002026       0.0941        46.43\n","          0.75     0.001949       0.0955        48.99\n","          0.80     0.001871       0.0971        51.88\n","          0.85     0.001802       0.1016        56.38\n","\n","------------------------------------------------------------\n","  PHASE 6: Summary Statistics\n","------------------------------------------------------------\n","\n","  TREATMENT SUMMARY:\n","  Metric                           Ketamine            SSRI    Neurosteroid\n","  ---------------------------------------------------------------------------\n","  Dose Range (L1)           0.0045-0.0138   0.0002-0.0009   0.0018-0.0025\n","  Best Acute Persev                  0.2333          0.6619          0.6298\n","  Best Relapse                     +0.0175         -0.0135         +0.1426\n","  Max Efficiency                     104.01           73.68           56.38\n","  Mean Efficiency                     60.78           58.70           42.95\n","\n","\n","                      DETAILED ISO-DOSE COMPARISON RESULTS                      \n","\n","\n","  TARGET DOSE: 0.005000\n","  ==========================================================================================\n","\n","  Treatment       Parameter               Dose L1   Turnover  Sparsity   Acute Prsv    Relapse \n","  ------------------------------------------------------------------------------------------\n","  Ketamine        regrow_fraction=0.1    0.004506     0.1254     0.0946       0.2627      +0.0508\n","  Ssri            epochs=200             0.000944     0.0131     0.0000       0.6619      +0.1662\n","  Neurosteroid    strength=0.5           0.002474     0.0405     0.0000       0.6563      +0.1492\n","\n","  OUTCOME COMPARISON AT THIS DOSE LEVEL:\n","    Best acute perseveration: Ketamine (0.2627)\n","    Best relapse resistance:  Ketamine ( = +0.0508)\n","    >> KETAMINE dominates at this dose level\n","\n","  TARGET DOSE: 0.010000\n","  ==========================================================================================\n","\n","  Treatment       Parameter               Dose L1   Turnover  Sparsity   Acute Prsv    Relapse \n","  ------------------------------------------------------------------------------------------\n","  Ketamine        regrow_fraction=0.5    0.009600     0.4926     0.4732       0.2333      +0.0983\n","  Ssri            epochs=200             0.000944     0.0131     0.0000       0.6619      +0.1662\n","  Neurosteroid    strength=0.5           0.002474     0.0405     0.0000       0.6563      +0.1492\n","\n","  OUTCOME COMPARISON AT THIS DOSE LEVEL:\n","    Best acute perseveration: Ketamine (0.2333)\n","    Best relapse resistance:  Ketamine ( = +0.0983)\n","    >> KETAMINE dominates at this dose level\n","\n","\n","                        ISO-DOSE EXPERIMENT CONCLUSIONS                         \n","\n","\n","  ISO-DOSE COMPARISON FINDINGS:\n","  \n","  1. DOSE QUANTIFICATION:\n","     - L1 weight change norm provides mechanism-agnostic dose measurement\n","     - Ketamine produces highest dose (structural regrowth)\n","     - SSRI produces moderate dose (gradual weight refinement)  \n","     - Neurosteroid produces lowest dose (minimal weight changes, runtime modulation)\n","\n","  2. EFFICIENCY ANALYSIS:\n","     - Efficiency = outcome improvement per unit dose\n","     - Reveals which mechanism achieves most benefit with least network alteration\n","     - Critical for understanding treatment optimization\n","\n","  3. ISO-DOSE MATCHING:\n","     - At matched dose levels, treatments can be fairly compared\n","     - Removes bias from arbitrary hyperparameter scaling\n","     - Reveals inherent mechanism advantages vs parameter-driven effects\n","\n","  4. CLINICAL IMPLICATIONS:\n","     - High-efficiency treatments may be preferred when minimizing side effects\n","     - Low-dose/high-effect treatments may have better safety profiles\n","     - Dose-response curves guide titration strategies\n","    \n","\n","\n","                             EXPERIMENT COMPLETE                              \n","\n"]}]},{"cell_type":"markdown","source":["# The End"],"metadata":{"id":"8DknDX1LwP0a"}}]}